{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pysentiment2 as ps\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_term(terms): \n",
    "    search_term = \"\"\n",
    "    for term in terms: \n",
    "        if len(search_term) > 0: \n",
    "            search_term += \"|\" + str(term)\n",
    "        else: \n",
    "            search_term += str(term)\n",
    "    return search_term\n",
    "\n",
    "def get_subset_df(terms, df):\n",
    "    contain_df = df[df['full_text'].str.contains(get_search_term(terms), case = False)]\n",
    "    return contain_df.drop_duplicates(subset='full_text')\n",
    "        \n",
    "def get_num_stories_df(df): \n",
    "    df_new = df.set_index('date').index.value_counts().to_frame().sort_index().cumsum()\n",
    "    start_date = list(df_new.index)[0]\n",
    "    end_date = list(df_new.index)[-1]\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    df_new = df_new.reindex(idx, fill_value='NaN')\n",
    "    vals = []\n",
    "    for i in range(len(df_new)):\n",
    "        num = df_new.iloc[i].item()\n",
    "        if df_new.iloc[i].item() != \"NaN\":\n",
    "            vals.append(num)\n",
    "        else: \n",
    "            vals.append(vals[-1])\n",
    "\n",
    "    df_new['date'] = vals \n",
    "    return df_new\n",
    "\n",
    "def get_prop_df(df1, df2): \n",
    "    df_new = (get_num_stories_df(df1) * (1/get_num_stories_df(df2))).fillna(method='ffill')\n",
    "    start_date = list(df_new.index)[0]\n",
    "    end_date = list(df_new.index)[-1]\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    df_new = df_new.reindex(idx, fill_value='NaN')\n",
    "    vals = []\n",
    "    for i in range(len(df_new)):\n",
    "        num = df_new.iloc[i].item()\n",
    "        if df_new.iloc[i].item() != \"NaN\":\n",
    "            vals.append(num)\n",
    "        else: \n",
    "            vals.append(vals[-1])\n",
    "\n",
    "    df_new['date'] = vals \n",
    "    df_new = df_new.fillna(0)\n",
    "    return df_new\n",
    "\n",
    "def get_num_stories_df_noncum(df): \n",
    "    return df.set_index('date').index.value_counts().to_frame().sort_index()\n",
    "\n",
    "def get_num_reactions_df(df): \n",
    "    df_new = df.groupby('date').sum().cumsum()['reactions']\n",
    "    start_date = list(df_new.index)[0]\n",
    "    end_date = list(df_new.index)[-1]\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    df_new = df_new.reindex(idx, fill_value='NaN')\n",
    "    vals = []\n",
    "    for i in range(len(df_new)):\n",
    "        num = df_new.iloc[i]\n",
    "        if num != \"NaN\":\n",
    "            vals.append(num)\n",
    "        else: \n",
    "            vals.append(vals[-1])\n",
    "    return pd.DataFrame({'index': idx, 'reactions': vals}).set_index('index')\n",
    "\n",
    "def get_prop_df_reactions(df1, df2): \n",
    "    start_date = list(df2['date'])[0]\n",
    "    end_date = list(df2['date'])[-1]\n",
    "    df_new = (get_num_reactions_df(df1) * (1/get_num_reactions_df(df2))).fillna(method='ffill')\n",
    "    idx = pd.date_range(start_date, end_date)\n",
    "    df_new = df_new.reindex(idx, fill_value='NaN')\n",
    "#     vals = []\n",
    "#     for i in range(len(df_new)):\n",
    "#         num = df_new.iloc[i].item()\n",
    "#         if df_new.iloc[i].item() != \"NaN\":\n",
    "#             vals.append(num)\n",
    "#         else: \n",
    "#             vals.append(vals[-1])\n",
    "\n",
    "#     df_new['date'] = vals \n",
    "    df_new = df_new.fillna(0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sentiment analysis\n",
    "def get_rolling_av_df(days_back, df): \n",
    "    start_date = df['date'].min()\n",
    "    end_date = df['date'].max()\n",
    "    \n",
    "    date_list = [] \n",
    "    sent_score_batch_list = [] \n",
    "    while start_date <= end_date: \n",
    "        date_list.append(start_date)\n",
    "        sent_score_batch_list.append(get_sent_score_batch(days_back, start_date, df))\n",
    "        start_date += dt.timedelta(1)\n",
    "    \n",
    "    df_roll = pd.DataFrame()\n",
    "    df_roll['date'] = date_list \n",
    "    df_roll['sent_score'] = sent_score_batch_list\n",
    "    df_roll = df_roll.set_index('date')\n",
    "    return df_roll\n",
    "             \n",
    "def get_sent_score_batch(days_back, today, df): \n",
    "    return df[(df['date'] >= today - dt.timedelta(days_back)) & (df['date'] <= today)]['sent_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for regression data\n",
    "def get_reg_data(sent_df, ndq_df, freq_): \n",
    "    master_df = pd.merge(sent_df, ndq_df, left_on='date', right_on='Date', how='right').sort_values('Date')\n",
    "    g = master_df.groupby(pd.Grouper(key='Date', freq=freq_))\n",
    "    dfs = [group for _,group in g]\n",
    "    returns_list, sent_list, date_list, sent_overval_list, sent_non_overval_list, vol_returns_list, volume_list, volume_list_raw, disagreement = ([] for i in range(9))\n",
    "    \n",
    "    for df in dfs: \n",
    "        try: \n",
    "            if freq_ != 'D': \n",
    "                returns_list.append((list(df['Close'])[-1]/list(df['Close'])[0] - 1) * 100)\n",
    "            else: \n",
    "                returns_list.append(list(df['Return'])[0])\n",
    "            date_list.append(list(df['Date'])[-1])\n",
    "            sent_list.append(df['sent_score'].dropna().mean())\n",
    "            sent_overval_list.append(df[df['flag'] == 1]['sent_score'].dropna().mean())\n",
    "            sent_non_overval_list.append(df[df['flag'] == 0]['sent_score'].dropna().mean())\n",
    "        except: \n",
    "            pass\n",
    "        try: \n",
    "            volume_list.append((list(df['Volume'])[-1]/list(df['Volume'])[0] - 1) * 100)\n",
    "            volume_list_raw.append(sum(list(df['Volume'])))\n",
    "        except: \n",
    "            volume_list.append(np.nan)\n",
    "            volume_list_raw.append(np.nan)\n",
    "        try: \n",
    "            vol_returns_list.append(np.array(list(set(df['close_return']))).std())\n",
    "        except: \n",
    "            vol_returns_list.append(np.nan)\n",
    "        try: \n",
    "            disagreement.append(np.array(list(set(df['sent_score']))).std())\n",
    "        except: \n",
    "            disagreement.append(np.nan)\n",
    "            \n",
    "    reg_df = pd.DataFrame({'date': date_list, \n",
    "                           'sent': sent_list, \n",
    "                           'returns': returns_list,\n",
    "                           'volat': vol_returns_list,\n",
    "                           'vol_ch': volume_list,\n",
    "                           'vol_raw': volume_list_raw,\n",
    "                           'sent_overval': sent_overval_list, \n",
    "                           'sent_non_overval': sent_non_overval_list, \n",
    "                           'disagree': disagreement})\n",
    "    \n",
    "    return reg_df \n",
    "\n",
    "\n",
    "def get_flags(fdata_twitter): \n",
    "    overval_terms = ['bubble', 'overval', \"too high\",'crash', 'collapse', 'mania', 'burst', \n",
    "                     'sky-high', 'lost its senses', 'strange', 'bizarre', 'psychology', 'implode', \n",
    "                     'black hole', 'unwarrant', 'irrational', 'tulip', 'euphori',\n",
    "                     'short sell', 'bandwagon', 'dot-com', 'dot com']\n",
    "\n",
    "    overval_df = get_subset_df(overval_terms, fdata_twitter)\n",
    "    nonoverval_df = pd.concat([overval_df, fdata_twitter]).drop_duplicates(keep=False)\n",
    "\n",
    "    list_id = list(overval_df['full_text'])\n",
    "    id_flag = [] \n",
    "    for i in range(len(fdata_twitter)): \n",
    "        storeid = fdata_twitter.iloc[i]['full_text']\n",
    "        if storeid in list_id: \n",
    "            id_flag.append(1)\n",
    "        else: \n",
    "            id_flag.append(0)\n",
    "\n",
    "    fdata_twitter['flag']=id_flag\n",
    "    return fdata_twitter\n",
    "\n",
    "def get_pct_change(df, col): \n",
    "    ret = [(df[col].iloc[i] - df[col].iloc[i-1])/df[col].iloc[i-1] for i in range(len(df))]\n",
    "    return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
